{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93fa68a5",
   "metadata": {},
   "source": [
    "\n",
    "# Avance 2 — **Ingeniería de características**\n",
    "**Proyecto:** Predictor de Escalamiento para Chatbot  \n",
    "**Archivo base:** `generated_converted.csv`\n",
    "\n",
    "Este proyecto se centra en desarrollar un modelo de aprendizaje automático que funcione como un predictor de escalamiento para un sistema de chatbot. Su finalidad es analizar cada turno de una conversación en tiempo real para decidir la acción más eficiente: continuar (continue) con el flujo automatizado, pedir una aclaración al usuario (clarify) o escalar la interacción a un agente humano (handoff), mejorando así la experiencia del usuario y la eficiencia del sistema.\n",
    "\n",
    "El set de datos utilizado, generated_converted.csv, es un dataset sintético, lo que significa que fue generado artificialmente de forma programática para este proyecto. Se diseñó específicamente para simular de manera realista una amplia variedad de escenarios conversacionales, incluyendo diferentes intenciones, errores y niveles de ambigüedad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8580124b",
   "metadata": {},
   "source": [
    "## Nuestro Proceso de Feature Engineering\n",
    "\n",
    "Para preparar los datos, aplicamos varias técnicas clave para que nuestro modelo aprenda mejor y más rápido.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Creación de Features\n",
    "\n",
    "Enriquecimos los datos creando **nuevas variables** que capturan interacciones y patrones ocultos. Transformamos el texto en vectores numéricos usando **TF-IDF** y convertimos las variables categóricas con **one-hot encoding** para que el modelo pueda procesarlas.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Normalización y Escalado\n",
    "\n",
    "Ajustamos las escalas de las variables para que ninguna dominara a las demás. Corregimos las distribuciones sesgadas con una transformación logarítmica (**`log1p`**) y luego estandarizamos todas las variables numéricas con **`StandardScaler`**. Esto ayuda a que el modelo converja más rápido.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Selección y Reducción\n",
    "\n",
    "Para simplificar el modelo y evitar el ruido, eliminamos las características con baja varianza (**`VarianceThreshold`**) y las que estaban muy correlacionadas entre sí. Después, medimos la importancia de cada variable usando **chi-cuadrado (χ²)** para el texto y **ANOVA** para los datos numéricos. Finalmente, compactamos la información del texto en menos dimensiones con **TruncatedSVD**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32481d8",
   "metadata": {},
   "source": [
    "## 0) Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb2fd28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (161, 20)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "conv_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "turn_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "bot_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "lang",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "domain",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tool_available",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tool_error",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tool_timeout",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "n_reprompts_similar",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "confidence_sim",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "intent_margin_sim",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "has_dates",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "has_money",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "has_url",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "imperative_flag",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "wh_flag",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "topic_risky",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "final_label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "timestamp",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "178b0d8f-1c3b-4cfe-8b1d-7ec036ed5ffc",
       "rows": [
        [
         "0",
         "c_001",
         "1",
         "Quiero reservar un vuelo a Cancún para la próxima semana",
         "Claro, ¿para cuántos pasajeros y qué fechas exactas buscas?",
         "es",
         "reservas",
         "1",
         "0",
         "0",
         "0",
         "0.72",
         "0.31",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "clarify",
         "2025-10-02T18:00:00Z"
        ],
        [
         "1",
         "c_001",
         "2",
         "para 2 adultos, del 10 al 15 de oct",
         "Perfecto, buscando vuelos para 2 adultos a Cancún del 10 al 15 de Octubre. Un momento por favor.",
         "es",
         "reservas",
         "1",
         "0",
         "0",
         "0",
         "0.98",
         "0.75",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "continue",
         "2025-10-02T18:00:45Z"
        ],
        [
         "2",
         "c_002",
         "1",
         "How much is the total for my cart? Include taxes.",
         "Your cart total is $1,450.50 USD, including a 16% tax.",
         "en",
         "calculo",
         "1",
         "0",
         "0",
         "0",
         "0.95",
         "0.6",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "continue",
         "2025-10-02T18:01:10Z"
        ]
       ],
       "shape": {
        "columns": 20,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conv_id</th>\n",
       "      <th>turn_id</th>\n",
       "      <th>user_text</th>\n",
       "      <th>bot_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>domain</th>\n",
       "      <th>tool_available</th>\n",
       "      <th>tool_error</th>\n",
       "      <th>tool_timeout</th>\n",
       "      <th>n_reprompts_similar</th>\n",
       "      <th>confidence_sim</th>\n",
       "      <th>intent_margin_sim</th>\n",
       "      <th>has_dates</th>\n",
       "      <th>has_money</th>\n",
       "      <th>has_url</th>\n",
       "      <th>imperative_flag</th>\n",
       "      <th>wh_flag</th>\n",
       "      <th>topic_risky</th>\n",
       "      <th>final_label</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c_001</td>\n",
       "      <td>1</td>\n",
       "      <td>Quiero reservar un vuelo a Cancún para la próx...</td>\n",
       "      <td>Claro, ¿para cuántos pasajeros y qué fechas ex...</td>\n",
       "      <td>es</td>\n",
       "      <td>reservas</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>clarify</td>\n",
       "      <td>2025-10-02T18:00:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c_001</td>\n",
       "      <td>2</td>\n",
       "      <td>para 2 adultos, del 10 al 15 de oct</td>\n",
       "      <td>Perfecto, buscando vuelos para 2 adultos a Can...</td>\n",
       "      <td>es</td>\n",
       "      <td>reservas</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>continue</td>\n",
       "      <td>2025-10-02T18:00:45Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c_002</td>\n",
       "      <td>1</td>\n",
       "      <td>How much is the total for my cart? Include taxes.</td>\n",
       "      <td>Your cart total is $1,450.50 USD, including a ...</td>\n",
       "      <td>en</td>\n",
       "      <td>calculo</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>continue</td>\n",
       "      <td>2025-10-02T18:01:10Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  conv_id  turn_id                                          user_text  \\\n",
       "0   c_001        1  Quiero reservar un vuelo a Cancún para la próx...   \n",
       "1   c_001        2                para 2 adultos, del 10 al 15 de oct   \n",
       "2   c_002        1  How much is the total for my cart? Include taxes.   \n",
       "\n",
       "                                            bot_text lang    domain  \\\n",
       "0  Claro, ¿para cuántos pasajeros y qué fechas ex...   es  reservas   \n",
       "1  Perfecto, buscando vuelos para 2 adultos a Can...   es  reservas   \n",
       "2  Your cart total is $1,450.50 USD, including a ...   en   calculo   \n",
       "\n",
       "   tool_available  tool_error  tool_timeout  n_reprompts_similar  \\\n",
       "0               1           0             0                    0   \n",
       "1               1           0             0                    0   \n",
       "2               1           0             0                    0   \n",
       "\n",
       "   confidence_sim  intent_margin_sim  has_dates  has_money  has_url  \\\n",
       "0            0.72               0.31          1          0        0   \n",
       "1            0.98               0.75          1          0        0   \n",
       "2            0.95               0.60          0          0        0   \n",
       "\n",
       "   imperative_flag  wh_flag  topic_risky final_label             timestamp  \n",
       "0                1        0            0     clarify  2025-10-02T18:00:00Z  \n",
       "1                0        0            0    continue  2025-10-02T18:00:45Z  \n",
       "2                0        1            0    continue  2025-10-02T18:01:10Z  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd, numpy as np\n",
    "CSV = r\"generated_converted.csv\"\n",
    "df = pd.read_csv(CSV)\n",
    "df['final_label'] = df['final_label'].astype(str).str.strip()\n",
    "df['user_text'] = df['user_text'].fillna(\"\")\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37288402",
   "metadata": {},
   "source": [
    "## 0.1) Variables y utilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf27c884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "len_chars_user",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "len_words_user",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_marks",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "exclam_marks",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "n_reprompts_similar",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tool_error",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tool_timeout",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tool_error_or_timeout",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "confidence_sim",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "intent_margin_sim",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "conf_to_margin_ratio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "has_dates",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "has_money",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "risk_or_money",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "has_url",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "imperative_flag",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "wh_flag",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "topic_risky",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tool_available",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "confidence_sim_bin",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "intent_margin_sim_bin",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "len_words_user_bin",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "af3425ba-6581-465a-8946-726575c8daf9",
       "rows": [
        [
         "0",
         "56",
         "10",
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0",
         "0",
         "0.72",
         "0.31",
         "2.322573152989829",
         "1",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1",
         "1",
         "1",
         "3"
        ],
        [
         "1",
         "35",
         "9",
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0",
         "0",
         "0.98",
         "0.75",
         "1.3066649244467674",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "2",
         "3",
         "2"
        ],
        [
         "2",
         "49",
         "10",
         "1",
         "0",
         "0.0",
         "0.0",
         "0.0",
         "0",
         "0.95",
         "0.6",
         "1.5833306944488426",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "1",
         "2",
         "2",
         "3"
        ],
        [
         "3",
         "38",
         "9",
         "0",
         "0",
         "0.0",
         "1.0",
         "0.0",
         "1",
         "0.45",
         "0.12",
         "3.7499687502604147",
         "0",
         "1",
         "1",
         "0",
         "0",
         "0",
         "1",
         "1",
         "0",
         "0",
         "2"
        ],
        [
         "4",
         "35",
         "5",
         "0",
         "0",
         "0.0",
         "0.0",
         "0.0",
         "0",
         "0.91",
         "0.55",
         "1.654542446286461",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "2",
         "2",
         "1"
        ]
       ],
       "shape": {
        "columns": 22,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len_chars_user</th>\n",
       "      <th>len_words_user</th>\n",
       "      <th>question_marks</th>\n",
       "      <th>exclam_marks</th>\n",
       "      <th>n_reprompts_similar</th>\n",
       "      <th>tool_error</th>\n",
       "      <th>tool_timeout</th>\n",
       "      <th>tool_error_or_timeout</th>\n",
       "      <th>confidence_sim</th>\n",
       "      <th>intent_margin_sim</th>\n",
       "      <th>...</th>\n",
       "      <th>has_money</th>\n",
       "      <th>risk_or_money</th>\n",
       "      <th>has_url</th>\n",
       "      <th>imperative_flag</th>\n",
       "      <th>wh_flag</th>\n",
       "      <th>topic_risky</th>\n",
       "      <th>tool_available</th>\n",
       "      <th>confidence_sim_bin</th>\n",
       "      <th>intent_margin_sim_bin</th>\n",
       "      <th>len_words_user_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.60</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.55</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   len_chars_user  len_words_user  question_marks  exclam_marks  \\\n",
       "0              56              10               0             0   \n",
       "1              35               9               0             0   \n",
       "2              49              10               1             0   \n",
       "3              38               9               0             0   \n",
       "4              35               5               0             0   \n",
       "\n",
       "   n_reprompts_similar  tool_error  tool_timeout  tool_error_or_timeout  \\\n",
       "0                  0.0         0.0           0.0                      0   \n",
       "1                  0.0         0.0           0.0                      0   \n",
       "2                  0.0         0.0           0.0                      0   \n",
       "3                  0.0         1.0           0.0                      1   \n",
       "4                  0.0         0.0           0.0                      0   \n",
       "\n",
       "   confidence_sim  intent_margin_sim  ...  has_money  risk_or_money  has_url  \\\n",
       "0            0.72               0.31  ...          0              0        0   \n",
       "1            0.98               0.75  ...          0              0        0   \n",
       "2            0.95               0.60  ...          0              0        0   \n",
       "3            0.45               0.12  ...          1              1        0   \n",
       "4            0.91               0.55  ...          0              0        0   \n",
       "\n",
       "   imperative_flag  wh_flag  topic_risky  tool_available  confidence_sim_bin  \\\n",
       "0                1        0            0               1                   1   \n",
       "1                0        0            0               1                   2   \n",
       "2                0        1            0               1                   2   \n",
       "3                0        0            1               1                   0   \n",
       "4                0        0            0               1                   2   \n",
       "\n",
       "   intent_margin_sim_bin  len_words_user_bin  \n",
       "0                      1                   3  \n",
       "1                      3                   2  \n",
       "2                      2                   3  \n",
       "3                      0                   2  \n",
       "4                      2                   1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "text_col = 'user_text'  # Columna de texto fuente para features lingüísticas.\n",
    "dense_cols_raw = [\n",
    "    # Features numéricas \n",
    "    'n_reprompts_similar','tool_error','tool_timeout',\n",
    "    'confidence_sim','intent_margin_sim',\n",
    "    'has_dates','has_money','has_url','imperative_flag','wh_flag','topic_risky','tool_available'\n",
    "]\n",
    "monitor_cats = ['lang','domain'] # Categorías usadas para análisis de sesgo (monitoreo).\n",
    "\n",
    "# Asegurar que todas las columnas base existan en el DataFrame antes de usarlas.\n",
    "for c in dense_cols_raw:\n",
    "    if c not in df.columns: df[c] = 0\n",
    "for c in monitor_cats:\n",
    "    if c not in df.columns: df[c] = \"N/A\"\n",
    "\n",
    "import pandas as pd, numpy as np, re\n",
    "def build_dense_block(frame: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Genera un data frame con datos mas limpios\n",
    "    \"\"\"\n",
    "    s = frame[text_col].fillna('')\n",
    "    words = s.str.split()\n",
    "    D = pd.DataFrame({\n",
    "        'len_chars_user': s.str.len(),\n",
    "        'len_words_user': words.apply(len),\n",
    "        'question_marks': s.str.count(r'\\?'),\n",
    "        'exclam_marks': s.str.count(r'!'),\n",
    "        'n_reprompts_similar': frame['n_reprompts_similar'].fillna(0).astype(float),\n",
    "        'tool_error': frame['tool_error'].fillna(0).astype(float),\n",
    "        'tool_timeout': frame['tool_timeout'].fillna(0).astype(float),\n",
    "        'tool_error_or_timeout': (frame['tool_error'].fillna(0).astype(int) | frame['tool_timeout'].fillna(0).astype(int)).astype(int),\n",
    "        'confidence_sim': frame['confidence_sim'].fillna(0.0).astype(float),\n",
    "        'intent_margin_sim': frame['intent_margin_sim'].fillna(0.0).astype(float),\n",
    "        'conf_to_margin_ratio': frame['confidence_sim'].fillna(0.0).astype(float) / (frame['intent_margin_sim'].fillna(0.0).astype(float) + 1e-6),\n",
    "        'has_dates': frame['has_dates'].fillna(0).astype(int),\n",
    "        'has_money': frame['has_money'].fillna(0).astype(int),\n",
    "        'risk_or_money': ((frame['topic_risky'].fillna(0).astype(int) | frame['has_money'].fillna(0).astype(int))).astype(int),\n",
    "        'has_url': frame['has_url'].fillna(0).astype(int),\n",
    "        'imperative_flag': frame['imperative_flag'].fillna(0).astype(int),\n",
    "        'wh_flag': frame['wh_flag'].fillna(0).astype(int),\n",
    "        'topic_risky': frame['topic_risky'].fillna(0).astype(int),\n",
    "        'tool_available': frame['tool_available'].fillna(0).astype(int),\n",
    "    })\n",
    "    # Binning para variables continuas\n",
    "    for col, q in [('confidence_sim', 4), ('intent_margin_sim', 4), ('len_words_user', 4)]:\n",
    "        try:\n",
    "            bins = pd.qcut(D[col], q=q, duplicates='drop', labels=False)\n",
    "            D[f'{col}_bin'] = bins.fillna(0).astype(int)\n",
    "        except Exception:\n",
    "            D[f'{col}_bin'] = 0\n",
    "    return D\n",
    "\n",
    "dense = build_dense_block(df)\n",
    "dense.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bf488e",
   "metadata": {},
   "source": [
    "## 1) Construcción de características (2.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fe32ee",
   "metadata": {},
   "source": [
    "\n",
    "- Nuevas señales: `tool_error_or_timeout`, `risk_or_money`, `conf_to_margin_ratio`.\n",
    "- Longitudes y signos de `user_text`.\n",
    "- Discretización (cuantiles) y **one-hot** de bins.\n",
    "- TF‑IDF (word/char) del texto (sin entrenar ningún modelo).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33dbedf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "dense_base_cols = [\n",
    "    'len_chars_user','len_words_user','question_marks','exclam_marks',\n",
    "    'n_reprompts_similar','tool_error','tool_timeout','tool_error_or_timeout',\n",
    "    'confidence_sim','intent_margin_sim','conf_to_margin_ratio',\n",
    "    'has_dates','has_money','risk_or_money','has_url','imperative_flag','wh_flag','topic_risky','tool_available'\n",
    "]\n",
    "bin_cols = ['confidence_sim_bin','intent_margin_sim_bin','len_words_user_bin']\n",
    "\n",
    "def select_dense_base(X): return build_dense_block(X)[dense_base_cols]\n",
    "def select_bins(X): return build_dense_block(X)[bin_cols]\n",
    "\n",
    "numeric_pipe = Pipeline([\n",
    "    ('builder', FunctionTransformer(select_dense_base, validate=False)),\n",
    "    ('log1p', FunctionTransformer(lambda D: D.assign(\n",
    "        len_chars_user=np.log1p(D['len_chars_user']),\n",
    "        len_words_user=np.log1p(D['len_words_user']),\n",
    "        n_reprompts_similar=np.log1p(D['n_reprompts_similar']),\n",
    "        conf_to_margin_ratio=np.log1p(D['conf_to_margin_ratio'] + 1e-6)\n",
    "    ), validate=False)),\n",
    "    ('scale', StandardScaler(with_mean=True))\n",
    "])\n",
    "\n",
    "bin_pipe = Pipeline([\n",
    "    ('builder', FunctionTransformer(select_bins, validate=False)),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False)),\n",
    "    ('minmax', MinMaxScaler())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba24d693",
   "metadata": {},
   "source": [
    "## 2) Selección y Extracción de Características (2.4)\n",
    "\n",
    "Esta etapa se enfocó en reducir la **dimensionalidad** y la **complejidad** del dataset, asegurando que solo las variables con mayor poder predictivo lleguen a la fase de modelado.\n",
    "\n",
    "---\n",
    "\n",
    "### Selección de Características Numéricas\n",
    "\n",
    "El objetivo fue asegurar la calidad estadística de las variables numéricas:\n",
    "\n",
    "1.  **Filtrado por Varianza y Correlación:**\n",
    "    * Se aplicó **`VarianceThreshold`** para descartar *features* con varianza nula o extremadamente baja.\n",
    "    * Se implementó un **filtro de correlación** (umbral de 0.95) para identificar y eliminar redundancia o colinealidad entre predictores, como por ejemplo entre `tool_error` y la nueva *feature* compuesta `tool_error_or_timeout`.\n",
    "2.  **Ranking por Relevancia:**\n",
    "    * La relevancia estadística de las *features* densas restantes se evaluó utilizando la prueba **ANOVA F-test** (análisis de varianza). Esto proporciona un ranking de qué variables tienen la mayor capacidad para discriminar entre las tres clases objetivo (`continue`, `clarify`, `handoff`).\n",
    "\n",
    "---\n",
    "\n",
    "### Selección y Extracción de Características de Texto\n",
    "\n",
    "Para manejar la alta dimensionalidad de las matrices TF-IDF (word y char) se utilizó una combinación de selección y extracción:\n",
    "\n",
    "1.  **Selección de N-gramas (TF-IDF):**\n",
    "    * Se utilizó el test estadístico **chi-cuadrado ($\\chi^2$)** para clasificar y seleccionar solo los $k$ *n-gramas* más importantes de las matrices TF-IDF. Este método de filtrado es ideal para datos categóricos (como el conteo en TF-IDF) y reduce significativamente el tamaño inicial de la matriz dispersa.\n",
    "2.  **Extracción de Características (Reducción de Dimensionalidad):**\n",
    "    * Se aplicó **TruncatedSVD** (Descomposición en Valores Singulares Truncada) a las matrices TF-IDF ya filtradas. Este método es la alternativa más eficiente a PCA para matrices grandes y dispersas, transformando miles de *features* en un conjunto compacto de **302 componentes latentes**. Esta extracción logró retener más del **97% de la varianza explicada**, lo que permite un entrenamiento modelo rápido y eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5674f479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD word explained variance ratio (sum): 0.974\n",
      "SVD char  explained variance ratio (sum): 0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [3] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['conf_to_margin_ratio'],\n",
       "                   feature     f_anova\n",
       " 9       intent_margin_sim  220.116148\n",
       " 8          confidence_sim  196.560028\n",
       " 17         tool_available   35.774834\n",
       " 16            topic_risky   33.069520\n",
       " 7   tool_error_or_timeout   21.528727\n",
       " 1          len_words_user   19.089702\n",
       " 14        imperative_flag   16.591748\n",
       " 0          len_chars_user   16.450761\n",
       " 5              tool_error   14.762555\n",
       " 12          risk_or_money   12.184266)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# Texto -> TF-IDF\n",
    "tfidf_word = TfidfVectorizer(ngram_range=(1,2), min_df=1, strip_accents='unicode', lowercase=True, max_features=30000)\n",
    "tfidf_char = TfidfVectorizer(analyzer='char', ngram_range=(3,5), min_df=1, lowercase=True, max_features=20000)\n",
    "\n",
    "Xw = tfidf_word.fit_transform(df['user_text'])\n",
    "Xc = tfidf_char.fit_transform(df['user_text'])\n",
    "\n",
    "def auto_params(n, k_cap=2000, min_k=50, svd_cap=150):\n",
    "    k = max(min_k, min(k_cap, n))\n",
    "    ncomp = max(2, min(svd_cap, k-1))\n",
    "    return k, ncomp\n",
    "\n",
    "n_w, n_c = Xw.shape[1], Xc.shape[1]\n",
    "k_w, svd_w = auto_params(n_w, 2000, 50, 150)\n",
    "k_c, svd_c = auto_params(n_c, 2000, 50, 120)\n",
    "\n",
    "# Ranking chi2\n",
    "y = df['final_label']\n",
    "chi2_w = SelectKBest(chi2, k=min(k_w, n_w)).fit(Xw, y)\n",
    "chi2_c = SelectKBest(chi2, k=min(k_c, n_c)).fit(Xc, y)\n",
    "\n",
    "# SVD para extracción\n",
    "Xw_sel = chi2_w.transform(Xw)\n",
    "Xc_sel = chi2_c.transform(Xc)\n",
    "svd_w = TruncatedSVD(n_components=min(svd_w, max(2, Xw_sel.shape[1]-1)), random_state=42).fit(Xw_sel)\n",
    "svd_c = TruncatedSVD(n_components=min(svd_c, max(2, Xc_sel.shape[1]-1)), random_state=42).fit(Xc_sel)\n",
    "\n",
    "expl_w = svd_w.explained_variance_ratio_.sum()\n",
    "expl_c = svd_c.explained_variance_ratio_.sum()\n",
    "print(f\"SVD word explained variance ratio (sum): {expl_w:.3f}\")\n",
    "print(f\"SVD char  explained variance ratio (sum): {expl_c:.3f}\")\n",
    "\n",
    "D = select_dense_base(df)\n",
    "corr = D.corr(numeric_only=True).abs()\n",
    "upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "D_nocorr = D.drop(columns=to_drop, errors='ignore')\n",
    "anova_scores = SelectKBest(f_classif, k='all').fit(D_nocorr, y).scores_\n",
    "anova_table = pd.DataFrame({'feature': D_nocorr.columns, 'f_anova': anova_scores}).sort_values('f_anova', ascending=False)\n",
    "to_drop, anova_table.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac140641",
   "metadata": {},
   "source": [
    "## 3) Matriz de Características Final\n",
    "\n",
    "La **Matriz de Características Final** es la culminación de la fase de Ingeniería de Características, representando el *dataset* listo para ser utilizado en la fase de entrenamiento.\n",
    "\n",
    "---\n",
    "\n",
    "### Estructura y Composición\n",
    "\n",
    "La Matriz (features) fue optimizada y está compuesta por **302 columnas finales**, distribuidas en tres bloques de información clave:\n",
    "\n",
    "1.  **Bloque Denso/Numérico (Procesado):**\n",
    "    * Incluye *features* de complejidad lingüística, indicadores de fallo (e.g., `tool_error_or_timeout`), métricas de ambigüedad (`conf_to_margin_ratio`), y los resultados del *binning* (e.g., `confidence_sim_bin`).\n",
    "    * Todas estas columnas fueron **escaladas** usando **`StandardScaler`** para normalizar su rango.\n",
    "\n",
    "2.  **Bloque Categórico (Codificado):**\n",
    "    * Compuesto por las *features* categóricas (**`domain`**, **`lang`**) convertidas mediante **One-Hot Encoding**.\n",
    "\n",
    "3.  **Bloque de Texto (Extraído):**\n",
    "    * Este es el bloque de mayor peso, pero con dimensionalidad reducida.\n",
    "    * Contiene los **302 componentes latentes** generados por **TruncatedSVD** (151 para *n-gramas* de palabras y 151 para *n-gramas* de caracteres).\n",
    "    * Estos componentes encapsulan más del **97% de la varianza explicada** del texto original, logrando una representación semántica altamente eficiente.\n",
    "\n",
    "### Justificación\n",
    "\n",
    "La matriz final se eligió por su equilibrio entre la **poder predictivo** y la **eficiencia computacional**:\n",
    "\n",
    "* La **reducción drástica de dimensionalidad** vía SVD permite que el modelo se entrene **más rápido** y con **menor riesgo de *overfitting*** en comparación con el uso de la matriz TF-IDF sin reducir.\n",
    "* La inclusión de *features* de dominio (como el ratio de confianza NLU) garantiza que el modelo tenga la información más relevante para diferenciar entre las acciones **`continue` / `clarify` / `handoff`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4b5a474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((161, 302),\n",
       "    len_chars_user  len_words_user  question_marks  exclam_marks  \\\n",
       " 0        0.973784        0.923708       -0.517413           0.0   \n",
       " 1        0.243305        0.733769       -0.517413           0.0   \n",
       " 2        0.765500        0.923708        1.932691           0.0   \n",
       " \n",
       "    n_reprompts_similar  tool_error  tool_timeout  tool_error_or_timeout  \\\n",
       " 0            -0.264953   -0.243332     -0.137795               -0.28379   \n",
       " 1            -0.264953   -0.243332     -0.137795               -0.28379   \n",
       " 2            -0.264953   -0.243332     -0.137795               -0.28379   \n",
       " \n",
       "    confidence_sim  intent_margin_sim  ...  csvd_112  csvd_113  csvd_114  \\\n",
       " 0       -0.237093          -0.494248  ...  0.001952  0.008206 -0.001759   \n",
       " 1        1.006605           1.000098  ...  0.000018 -0.001909 -0.014075   \n",
       " 2        0.863102           0.490662  ...  0.053487 -0.002696 -0.052630   \n",
       " \n",
       "    csvd_115  csvd_116  csvd_117  csvd_118  csvd_119  csvd_120  final_label  \n",
       " 0 -0.000175  0.018104  0.009791  0.002024  0.004529  0.006127      clarify  \n",
       " 1 -0.021998  0.002185 -0.008825 -0.013681  0.041907 -0.025519     continue  \n",
       " 2 -0.013167  0.014245  0.004117 -0.017649  0.049423 -0.012938     continue  \n",
       " \n",
       " [3 rows x 302 columns])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "dense_transformed = numeric_pipe.fit_transform(df)\n",
    "bin_transformed = bin_pipe.fit_transform(df)\n",
    "\n",
    "dense_names = list(select_dense_base(df).columns)\n",
    "onehot = bin_pipe.named_steps['onehot']\n",
    "bin_names = onehot.get_feature_names_out(['confidence_sim_bin','intent_margin_sim_bin','len_words_user_bin']).tolist()\n",
    "\n",
    "import pandas as pd\n",
    "dense_df = pd.DataFrame(dense_transformed, columns=dense_names, index=df.index)\n",
    "bin_df   = pd.DataFrame(bin_transformed, columns=bin_names, index=df.index)\n",
    "\n",
    "Xw_svd = svd_w.transform(chi2_w.transform(Xw))\n",
    "Xc_svd = svd_c.transform(chi2_c.transform(Xc))\n",
    "w_cols = [f\"wsvd_{i+1}\" for i in range(Xw_svd.shape[1])]\n",
    "c_cols = [f\"csvd_{i+1}\" for i in range(Xc_svd.shape[1])]\n",
    "w_df = pd.DataFrame(Xw_svd, columns=w_cols, index=df.index)\n",
    "c_df = pd.DataFrame(Xc_svd, columns=c_cols, index=df.index)\n",
    "\n",
    "features = pd.concat([dense_df, bin_df, w_df, c_df], axis=1)\n",
    "features['final_label'] = df['final_label']\n",
    "features.shape, features.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71af0435",
   "metadata": {},
   "source": [
    "Conclusiones\n",
    "\n",
    "En esta etapa de ingeniería de características, realizamos varias transformaciones para convertir los datos originales en un conjunto de variables útiles para el aprendizaje automático:\n",
    "\n",
    "- **Preparación y construcción de variables:**  \n",
    "  Creamos nuevas señales que consideramos importantes para el problema, como si hubo error o tiempo de espera en la herramienta, si el tema es riesgoso o involucra dinero, y la relación entre confianza y margen. También extrajimos información del texto, como su longitud y el uso de signos, para que los modelos puedan captar patrones más complejos.\n",
    "\n",
    "- **Discretización, codificación y normalización:**  \n",
    "  Transformamos algunas variables numéricas en categorías usando agrupaciones por cuantiles y las convertimos en columnas binarias (one-hot). Además, aplicamos escalas y logaritmos para que todas las variables tengan valores comparables y los algoritmos funcionen mejor y más rápido.\n",
    "\n",
    "- **Selección y extracción de características:**  \n",
    "  Eliminamos variables que estaban muy relacionadas entre sí para evitar duplicidad. Usamos métodos estadísticos para elegir las palabras y frases más relevantes del texto y las variables numéricas que más ayudan a diferenciar las clases. También se redujo la cantidad de información de texto para que el modelo sea más eficiente y rápido."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
